WEBVTT

00:00:04.829 --> 00:00:09.186
A recap then. So far up until now,
we've looked at the relation

00:00:09.270 --> 00:00:13.289
between artificial intelligence,
machine learning and deep learning.

00:00:13.710 --> 00:00:17.579
So where does generative AI fit
into all of this?

00:00:18.180 --> 00:00:21.875
Well, you may have understood this already
because generative AI

00:00:21.959 --> 00:00:26.736
is a subset of deep learning.
It uses deep learning neural networks

00:00:26.819 --> 00:00:30.569
to understand the training data,
learn from it,

00:00:30.750 --> 00:00:37.439
and then generate new content.
The key important word here is generative

00:00:38.220 --> 00:00:43.445
or the ability to generate something new.
The existing AI system

00:00:43.529 --> 00:00:48.000
that we can call conventional AI systems,
they've operated

00:00:48.750 --> 00:00:54.180
in a non generative way up until around
about the period 2018-19.

00:00:54.779 --> 00:00:59.706
That is you gave them training data.
The model learned from it

00:00:59.790 --> 00:01:05.550
And then it made either predictions
or classified the data into categories.

00:01:06.720 --> 00:01:11.155
Ordered language processing
like translations or computer vision,

00:01:11.239 --> 00:01:16.856
and identified what an image was.
So you train a machine learning model

00:01:16.940 --> 00:01:20.150
on lots of images of,
say for example, apples,

00:01:20.510 --> 00:01:23.966
and then ask it to tell you
whether a supplied image

00:01:24.050 --> 00:01:28.136
is of an apple or not.
And it can do that for you.

00:01:28.220 --> 00:01:33.410
That's what conventional AI does.
That's what conventional AI is trained on

00:01:33.559 --> 00:01:38.246
and it's created to operate on.
Now, generative AI, on the other hand,

00:01:38.330 --> 00:01:43.466
is entirely different from that.
We give the AI model

00:01:43.550 --> 00:01:48.416
lots of training data,
much, much more training data

00:01:48.500 --> 00:01:52.790
than we have typically given
to a conversational AI system.

00:01:53.029 --> 00:01:56.786
And based on this training data
based on the neural network

00:01:56.870 --> 00:02:01.489
that operates behind the scene,
it's able to generate new content,

00:02:01.669 --> 00:02:06.529
whether it's text
or image or video or anything.

00:02:07.069 --> 00:02:10.130
So if we talk about the same example
that I mentioned earlier,

00:02:10.279 --> 00:02:13.766
we train our model this time
a generative AI model

00:02:13.850 --> 00:02:17.656
on the same data set of Apple images.
And then we ask you

00:02:17.740 --> 00:02:21.250
to generate an image of an apple for us.
Well, it can do that.

00:02:22.000 --> 00:02:27.250
It can give us this new image.
Now please note here that this image,

00:02:27.550 --> 00:02:30.166
it's not coming
from the millions of images

00:02:30.250 --> 00:02:34.636
that this model was trained on.
It's not an extractive task.

00:02:34.720 --> 00:02:40.906
It's a generative task.
The the model is generating

00:02:40.990 --> 00:02:45.166
a new image of the apple
based on what it has learned

00:02:45.250 --> 00:02:51.130
from this training data. And once again,
that is what generative AI is.

00:02:51.580 --> 00:02:54.975
You are generating new content
whether it's text,

00:02:55.059 --> 00:03:00.916
image, audio, video, using AI.
So I hope you're clear on this now.

00:03:01.000 --> 00:03:04.785
But before we look more in depth
in this

00:03:04.869 --> 00:03:08.649
eLearning about generative AI
and how it works behind the scenes,

00:03:09.130 --> 00:03:12.016
it's a it's applicability
and all those things, I want you

00:03:12.100 --> 00:03:17.350
to remember three takeaways
from what you've learned so far:

00:03:17.979 --> 00:03:20.716
Firstly, for machines
to be intelligent, to be accurate,

00:03:20.800 --> 00:03:25.615
you need to train them on large volumes
of data. And there's a term

00:03:25.699 --> 00:03:28.580
that's used in machine learning,
and that's 'Garbage in

00:03:28.759 --> 00:03:33.020
is the same as Garbage out'.
So if you feed garbage,

00:03:33.470 --> 00:03:38.300
garbage data or bad data to your machine,
to your machine learning model,

00:03:38.509 --> 00:03:42.139
obviously it will give bad results,
garbage results.

00:03:42.350 --> 00:03:44.750
On the other hand,
if you give it good data,

00:03:45.050 --> 00:03:49.490
various variations of data,
huge volumes of data,

00:03:49.610 --> 00:03:53.210
you'll obviously get better,
more accurate results.

00:03:54.320 --> 00:03:57.835
The second key takeaway
is that we need a lot

00:03:57.919 --> 00:04:01.315
of computational power.
We're feeding large volumes

00:04:01.399 --> 00:04:04.076
of training data.
We're using neural networks,

00:04:04.160 --> 00:04:07.496
which are very complex.
We're expecting quick answers,

00:04:07.580 --> 00:04:10.496
almost conversational
when we type in something

00:04:10.580 --> 00:04:15.626
into ChatGPT or Copilot or Claude
or whatever generative AI applications

00:04:15.710 --> 00:04:21.290
are using. So the computational power
behind the scene has to be massive.

00:04:22.250 --> 00:04:26.095
It has to be powerful to be able
to process this data

00:04:26.179 --> 00:04:30.655
in a very short amount of time.
And thirdly,

00:04:30.739 --> 00:04:33.175
we are seeing a shift in the way
that we interact

00:04:33.260 --> 00:04:37.779
with these machine learning models.
Users nowadays, me included.

00:04:38.260 --> 00:04:40.095
We don't necessarily
want to type in a query.

00:04:40.179 --> 00:04:43.335
We might want to speak in a query,
and instead of getting

00:04:43.420 --> 00:04:47.055
15 matching documents or links
and then read through each one,

00:04:47.140 --> 00:04:51.405
well, I'd like to have a summary of those.
So in a way,

00:04:51.489 --> 00:04:55.665
those days of the traditional tile style
of Google search,

00:04:55.750 --> 00:05:00.549
well, they're numbered because we want
conversational interaction ability.

00:05:01.269 --> 00:05:06.255
Um, when I say rather, I want
conversational interaction ability

00:05:06.339 --> 00:05:09.915
where I can put in a simple question
and I can get a direct answer,

00:05:10.000 --> 00:05:13.065
and I should be able to ask onwards
within context.

00:05:13.149 --> 00:05:16.215
So, for example,
if I ask what is the capital of Finland

00:05:16.299 --> 00:05:20.385
and get the answer Helsinki, which it is,
and then I go ahead and say,

00:05:20.470 --> 00:05:24.675
what's the weather like there?
Then the application that I'm using

00:05:24.760 --> 00:05:27.135
should understand
that I'm still talking about Helsinki.

00:05:27.220 --> 00:05:30.795
And then tell me about the weather there.
It should be able

00:05:30.880 --> 00:05:34.905
to understand that context.
It should be able to gather

00:05:34.989 --> 00:05:38.505
the information based on what
we've already been discussing,

00:05:38.589 --> 00:05:41.230
and then show me that continued result.

